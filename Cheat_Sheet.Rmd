---
title: "Cheat Sheet"
date: "`r Sys.Date()`"
author: "Justin Meisenhelter"
output: 
  rmdformats::downcute:
    highlight: tango
    df_print: paged
    collapsed: false
---

# Python  

## Syntax  
to put commands on new line use the backslash \\
```
8 * (7 + 6 * 5) \
      + 4 / 3 ** 2 - 1 
```

self assignment  
- `a=a+b` <----> `a+=b`  
- `a=a-b` <----> `a-=b`  
- `a=a*b` <----> `a*=b`  
- `a=a/b` <----> `a/=b`  

import libraries   
`import math`  
`from math import sin, cos`  
assign an alias for the module name    
`import math as ma`  

## Magic Commands  
autoreload
```
%load_ext autoreload
%autoreload 2
```


### _Jupyter NB Shortcuts_
group comment  
`crtl + /`
group indent  
`crtl + [`
show function documentation  
`shift + tab inside function`  
auto-complete  
`tab`

### Mathmatical Operators  
```
print(12 / 3)     # int / int -> float
print(17 // 3)    # floor division
print(17.0 // 3)  # return float if one of the values is float 
print(17 % 3)     # remainder
print(2 ** 7)     # 2 to the power of 7
```

## Indexing   

### Indexing a String  

`s[start_position:end_position:delta]`
```{python}
word = 'abcdefghijk'
word[-1:-3:-1]
```


### Reversing a string  

```{python}
word[::-1]

```

### Iterators  
```
x = [1,2,5]
x_iter = iter(x)
x_iter
next(x_iter)
```
converts a list into an interator object
the `next` function will return the first object and delete it calling the `next` function an additional time will return the second object and delete it.  
`x.pop()` will return the last element of a list and delte it  

### _enumerate_  
the enumerate() function takes an iterable and outputs a tuple pair of each elemenet and its index
```{python}
words = [0,2,4,6,8]
list(enumerate(words))
```

### String Methods  

https://www.w3schools.com/python/python_ref_string.asp
```{r, eval=FALSE}
word.upper()
word.lower()
word.strip()
word.replace()
word.split()
word.join()
word.find()
```

### _String Special Characters_  
\\t \<tab\>  
\\n \<newline\>  
r in front of a string makes it a raw string  
`print(r'C:\some\name')`  

## Functional Operators  

### _map_  
- You will often want to apply a function to all elements of a list.
- Suppose a list `L` has elements that are all numbers, and `f` is a function on numbers.  Then `map(f, L)` is the result of applying `f` to every element of `L`.
- The `map` function returns a map object, which is an **iterator**.  To get the list use the `list` function.
` map(<function>, <iterable>)` 
will apply the function to each element of the iterable  
returns a map object  

```
L = [4, 9, 16]
map(math.sqrt, L)
```

can use lambda functions as well  
`list(map(lambda val: val**.5, L))`
will take the square root of all elements of L  

### _filter_  

Filter extracts the elements of a list that satisfy some condition. The condition is given in the form of a boolean function.  

The `filter` function also returns an iterator object.  Use `list` to get the associated list.  

_to call filter we must pass a boolean function, a function that returns true or false_

```
def non_zero(x):
    return x != 0
list(filter(non_zero, [1, 2, 0, -3, 0, -5]))
```
will return all non zero elements of the list  

### _Multiple Arguments_
```
list(map(lambda x, y: x+y, [1,2,3], [10,20,30]))
```
will return the sum of element n of both lists  

### _zip_
takes two lists of the same length and makes one list containing pairs of the corresponding elements of the two lists  
```
a = [1, 2, 3, 4]
b = [5, 6, 7, 8]
list(zip(a, b))
# [(1, 5), (2, 6), (3, 7), (4, 8)]
```
```
list(map(lambda p: p[0]+p[1], zip([1,2,3], [10,20,30])))
# [11, 22, 33]
```
### **The operator module**

If you want to apply a built-in operation like `+` in a map, you can write a `lambda` function - `lambda x, y: x+y` - but there is a simpler way. The operator module defines named versions of the built-in operations, just for use in functions like `map`. For example:  
```
from operator import *
print(list(map(add, [1,2,3], [4, 5, 6])))
print(list(map(mul, [1,2,3], [4, 5, 6])))
# [5,7,9]
# [4, 10, 18]
```

### _Methods in map calls_
to call a method in a map call use a lambda function  
```
lis = [" abc \n", " def", "ghi   "]
list(map(lambda s: s.strip(), lis))
```

or use the class method call
`list(map(str.strip, lis))`

## Printing   

### _Format Specifier_  
- `format_specifier` is a string containing special format symbols, which are used to insert values from the tuple:  
  - `%s` means inserting a string.  
  - `%d` means inserting an integer.  
  - `%f` means inserting a float.  
```
print("hello, %f!" % 2017)
print("hello, %d!" % 2017)
print("hello, %.2f!" % 2017.1314)
```
### _format function_  

```
print('My name is {0} and I am {1} years old'.format('Mike', 25))
```
put index positions in curly brackets then `.format(0,1)  
```
print('My name is {name} and I am {age} years old'.format(name='Mike', age=25))
```

### _fast strings_  

define variables  
put an f in front of your string and the curly braces around variable names  
```
name = justin
age = 41
f'my name is {name} and mmy age is {age}
```

### Modulous Operator  

```{python}
print( "hello, %f!" %2017)
print( "hello, %i!" %2017)
print( "hello, %.2f!" %2017)
print( "hello, %s!" %'2017')

```
## Functions

```{python}
def square(x):  
    return x**2
```


### Default Arguments
```{python}
def polynomial(x, a, b=0, c=0, d=0):  #assigning default values
    result = a + b * x**1 + c * x**2 + d * x**3
    return result

```
```
def ask_ok(prompt, retries=4, complaint='Yes or no, please!'):
    while True:
        ok = input(prompt)   # In Python 2, it is called raw_input()
        if ok in ['y', 'ye', 'yes']:
            return True
        if ok in ['n', 'no', 'nop', 'nope']:
            return False
        retries = retries - 1
        if retries < 0:
            raise IOError('Not a good user.')
        print(complaint)
```
Note It is invalid in Python to put keyword argument in front of positional argument.  

### _\*args and \*\*kwargs_
- Sometimes your function has a number of input parameters but you don't want to specify all of them at the definition.   
- Then you can use `args` (tuple of arguments) and `kwargs` (keyword arguments) when you define the function.  

```{python}
args = (2,10,2)
list(range(*args))
```
```{python}
kwargs = {'arg1':5, 'arg2':10, 'arg3': -2}
def some_function(arg1, arg2, arg3):
  return arg1*arg2/arg3
some_function(**kwargs)
```

```{python}
def register_student(name, *args, **kwargs):
    print("-- The student's name is ", name)
    print("-" * 40)
    print(type(args))
    for arg in args:
        print(arg)
    print("-" * 40)
    print(type(kwargs))
    keys = sorted(kwargs.keys())
    for kw in keys:
        print(kw, ":", kwargs[kw])
```

#### _Unzipping a list_
```{python}
nested_list = [[1,2,3], [4,5,6], [7,8,9]]
# nested list is a zipped list
list(zip(*nested_list))
```



## Lambda Functions  
```
Add_two_powers = lambda x: x**2 + x**3
```
syntax: `lambda <variables>' : \<return statement\>  
Lambda functions can contain if else statements
```

Firstelt = lambda L: None if L==[] else L[0]
L1=[]
L2=[1,2,3]
print(Firstelt(L1))
print(Firstelt(L2))
```

## Control Flow  

### Else If  

```{python}
a=6
if type(a)==str:
    print('it is a string')
else:
    if a%2==0:
        print('it is an even number')
    else:
        print('it is an odd number')
```
```{python}
if type(a)==str:
    print('it is a string')
elif a%2==0:
    print('it is an even number')
else:
    print('it is an odd number')
```
### While Loops  

```{python}
x = 1
while x <= 10:
    if x % 2 == 0 and x % 3 != 0:
        print (x)
    x = x + 1

```
break and continue
```{python}
L = [10, -10, 20, -20, 30, -30, 40, -40, 50, -50, 60, -60]

sum_ = 0
for x in L:
    if x < 0:
# continue will skip the rest of the code and return to the opening loop
        continue
    sum_ = sum_ + x
    if sum_ > 100:
# break the outermost loop
        break
        
sum_

```
### for loops  

```{python}
for x in range(11):
    if x % 2 == 0 and x % 3 != 0:
        print (x)
```
multiple iterables
```
words = ['a', 'b', 'c', 'd', 'e']
for i, e in enumerate(words):
    print(i, e)
```
the enumerated list is unpacked and matched to the two indices

## Unpacking  
```{python}
def square_all(x, y):
    return x**2, y**2
x, y = square_all(2,3)
x, y
```
will assign the first output value to x and the second output value to y

## Handling Errors/Exceptions  

Python's **try** and **except** can provide ways to handle exceptions.

Exceptions raised by statements in the body of try are handled by the except statement and execution continues with the body of the except statement.  

```{python}
def divide(x, y):
    try:
        result =  x / y
    except ZeroDivisionError:
        result = 'INFINITY'
    except TypeError:
        result = divide(float(x), float(y))
    return result
```
## Lists

### Defining Lists
```{python}
x=[1,2,3,4,'1','a','hello']
print(x)
```
```{python}
#create an empty list
y = list()
```

### List Methods
```{python}
x.index('hello')
```
```{python}
x.append(55)
```
```{python}
x.extend([1,2,3])
# will add all elements in the list to the object x
```
```{python}
x.insert(2,'d')
# inserts 'd' into the index of 2
```
### _List Sorting_  
```{python}
staff =[['Lucy','A',9], ['John','B',3], ['Peter','A',6]]
sorted(staff, key = lambda x: x[1]) # key is the sort metric
```
```{python}
staff =[['Lucy','A',9], ['John','B',3], ['Peter','A',6]]
sorted(staff, key = lambda x: x[2]+len(x[0]))  # key is the sort metric
# will sort by length of name
```

### _Exersices_
Write a function to switch the ith and jth items in a list.
```
def switch_item(L, i, j):
    ... function body goes here ...

my_list = ['first', 'second', 'third', 'fourth']
switch_item(my_list, 1, -1)
my_list ---> ['first', 'fourth', 'third', 'second']
```
```{python}
def switch_item(L, i, j):
    temp = L[i]
    L[i] = L[j]
    L[j] = temp
    return L
my_list = ['first', 'second', 'third', 'fourth']
switch_item(my_list, 1, -1)
```
  

### List comprehension
the format of a list comprehension
```
[ <return expresion> for <element> in <list> if <boolean> ]
[ x* x for x in [1, 2, 3, 4, 5] if x%2 == 0] #map and filter
```
if you need an else statement
```
[ <expr1> if <boolean> else <expr2> for <element> in <list> ]
[ x* x if x%2 == 0 else x+2 for x in [1, 2, 3, 4, 5] ]
```
can chain together if elses
```
[x* x if x%2 == 0 else x+2 if x <3 else x *5 for x in [1, 2, 3, 4, 5]
```
can interact with previous iterations of the comprehension
```
x + p for p,x in zip([1,2,3,4,5], [1,2,3,4,5][1:])
```
```{python}
x=[200,400,23,50,1,23,54,66,88,97,20]
y=[i for i in x if i%2==0]
y
```
Write a list comprehension that takes a list of strings and returns the capitalized version of those strings if they are greater than 2 and fewer than 12 characters in length.
```{python}
names=['Barry White','aj','tom','John Foster Wallace',
       'Billy Bud','Yifan Ghost Song']
[i.upper() if len(i) > 2 and len(i) <12 else i for i in names]
```
### _Dictionary Comprehension_  
```{python}
dict_list = ['a', 'b', 'd', 'z']
{ letter:ord(letter) for letter in dict_list }
```
## Tuple  

Tuples are similar to lists in many ways, except they can't be modified once you've created them.  

Tuples are defined between two parentheses instead of brackets.  

Tuples are iterable but immutable.  
```{python}
tup=("hi", True, 1.0, 2)
tup

```

## Set  

A set is an unordered sequence of unique values. 
### Creating an empty set
```{python}
z=set() #creating an empty set
z
```
### Set Function
```{python}
s={1,2,3,3,3,4}
t={8,4,6,2}
s.difference(t)
s-t
s.intersection(t)
s&t
s.union(t)
s|t
s^t
# all non shared items in set
```
## Dictionary  

A dictionary is a set of keys with associated values. The key must be hashable, but the value can be any object. It is also known as a hash map, hash table or set of key-value pairs.  
```{python}
thing={}
thing['key1']='val1'
thing[2]='val2'
thing[3]=[3,2,1]

```
Can construct a dictionary from a list or set of tuples  
```
dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])
```

### Dictionary functions
```{python}
thing.keys()
thing.values()
thing.items()
thing.get('weight')
# thing.get(<key>, <value>) if key does not exist it will return the input value
```
### Word Frequency Histogram
```{python}
words=['hi','hello','hi','hi','yo','whazzup','hey','hey']
hist={}
for i in words:
    if i in hist:
        hist[i] += 1
    else:
        hist[i] = 1
hist

```
## Counter
```{python}
from collections import Counter, defaultdict
sentence = "this is a sentence and it has a bunch of letters and I want to count a few things"
my_counter = Counter(sentence)
my_counter
```
## Bitwise Operator
\& and \| are and and or respectively

```
10 & 1
# is a simple method for determining if an integer is even
```

## Recursion  
A function which calls itself  
```
def factorial(num):
    prod = 1
    while num > 0:
        prod *= num
        num -+ 1
    return prod
# for a recursive function we need a base case and a recusive call
# with recursion
def factorial_rec(num):
# base case
    if num == 0:
        return 1
# recursive call
    return num * facotrial_rec(num-1)

```
## Yield Statement
The yield statement is similar to return, however, it won’t return the whole result (say a very large list) at the end of the function but a generator instead.  
```
def ret(L):
    res = list(map(lambda x: x ** 2, L))
    return res
    
def gen(L):
    for i in L:
        yield i ** 2
# gives us a generator object
```
we now have a generator and can use the `next` function to return a recursive result   



## Web Scraping

example for the following sections:  
```
<html>
    <head>
        <title>Hi</title>
    </head>
    <body>
        <a href="https://www.crummy.com/software/BeautifulSoup/">Hello, BeautifulSoup!</a>
    </body>
</html>
```

with regular expressions, parse a file, hi.html and look for all expresions preceeded by `<title> any of letters <title>`
```
import re
hi_path = 'data/hi.html'
with open(hi_path, 'r') as f:
    hi = f.read()
    print(re.findall('<title>(.*)</title>', hi))
```
with beautiful soup
```
from bs4 import BeautifulSoup
with open(hi_path, 'r') as f:
    hi = f.read()
    hi = BeautifulSoup(hi, 'html.parser')
    print(hi.title) # find the title tag
    print(hi.title.string)  # find the value of tag
```
outputs a beautiful soup object

### Names, Values, and Attributes

BeautifulSoup can extract the `name`, `value`, and `attributes` of tags. The corresponding attributes are:  
- `name`
- `string`
- `attrs`

```
print("The name of a tags is: ", hi.a.name)
print("The value of a tags is: ", hi.a.string)
print("The attribute of a tags is: ", hi.a.attrs)
```
### get_text() & get()
`get_text() method will extract the values of the current tag and all its child tags
```
print(hi.html.get_text())
```
outputs:  `Hi`  


`Hello, BeautifulSoup!`

- The `get()` method is used to extract the value of a specific attribute of a tag. For example, we can get the `href` of the `a` tag using the following code.  

- This is the same as running `hi.a.attrs` first and then finding the value of key `href` from the `attrs` dictionary.  
```
print(hi.a.get('href'))
```
output: `https://www.crummy.com/software/BeautifulSoup/`

example for the following sections:  
```
<html>
    <head>
        <title>Article</title>
    </head>
    <body>
        <h1 id='one'>This is an h1 tag.</h1>
        <p>This is a paragraph, standard size font.</p>
        <h2>This is an h2 tag, smaller font.</h2>
        <p><a href='https://www.google.com'>This is a link to google.</a></p>
        <h3><a href='https://www.yelp.com/'>This is an h3 tag, even smaller.</a></h3>
        <p>And a normal p tag.</p>
    </body>
</html>
```
create a BeautifulSoup object from the article.html  
```
article_path = 'data/article.html'
with open(article_path, 'r') as f:
    article = f.read()
    article = BeautifulSoup(article, 'html.parser')
```
### _find()_
- `find()` returns the first `p` tag, which is equivalent to `article.p`:  
```
print(article.find('p'))
```
outputs: <p>This is a paragraph, standard size font.</p>    

- `find_all()` returns all descendant `p` tags as a resultset which is a subclass of list:
```
print(article.find_all('p'))
```
output: [<p>This is a paragraph, standard size font.</p>, <p><a href="https://www.google.com">This is a link to google.</a></p>, <p>And a normal p tag.</p>]  

- To find the tags that have specific attributes, you can pass a dictionary to the `attrs` argument with the key being the attribute name and the value being the value of the attribute:  
```
print(article.find_all('h1', attrs  = {'id':'one'}))
```
output: `[<h1 id="one">This is an h1 tag.</h1>]`

example:
The tags whose attribute id == 'one'   
```
print(article.find_all(lambda tag: tag.get('id') == 'one'))
```
output: `[<h1 id="one">This is an h1 tag.</h1>]`  

### _Web Scraping Example Books to Scrape_  
The general workflow of a web scraping project is the following:
1. Identify which fields we want to scrape. If this means we need to visit different URLs to get to the final page with our relevant information, how do we get those URLs?  
    - For this project, we're interested in the book title, UPC, price, genre, average rating, whether it's in stock, and how many books available.  
2. Find the unique attributes that will locate the tags of the elements that we're interested in.  
    - What elements are we interested in on the home page? How do we get every element from each search page? What elements do we want on the book pages?  
3. If there are multiple relevant pages in the project, test on the first page to make sure your code is extracting the correct elements.  
    - On the first results page, we can try to get all of the `href` attributes from each book product. We should get 20 total because there are 20 books per page.  
4. Once we know that our code is extracting the correct data, we can generalize the code to apply the scraping operations to every page.
5. The final data (the book information) should be stored in a `dict`. This will make saving the data easier.  
6. Once all the `dict` objects are populated, we can save the data locally as a JSON or CSV file (or other formats such as saving to SQL database or pickle file).  
```

from bs4 import BeautifulSoup
# request source code format, get request
import requests
# user agent is the software used to acess the site
# google, what is my user agent and copy/paste
headers = {'User-Agent':
           'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'
}
# check the response, 200 is good to go
response = requests.get('https://books.toscrape.com/', headers = headers)
text = BeautifulSoup(response.text, 'html.parser')
```
We can see that each book product has a `div` tag with `class` attribute "image_container." This tag has a child `a` tag that has an `href` attribute. The `href` attribute value is the URL to each of our book pages.  
```
\# We can check the length of the object that is returned to
\# (loosely) confirm that we are getting the correct content
len(text.find_all('div', attrs = {'class': 'image_container'}))

```
```

\# get the child a tags and subsequent href values
\# start with the location of the div tags
book_divs = text.find_all('div', attrs = {'class': 'image_container'})
\# use list comprehension to iterate over each tage to find the child a tag and get the href attribute
book_urls = [tag.find('a').get('href') for tag in book_divs]
print(book_urls[:5])
\# results are missing the domain
```
```
\#concat the domain url to book_urls
complete_book_urls = [f'https://books.toscrape.com/{end_part}' for end_part in book_urls]
print(complete_book_urls[:5])

```
Now we have complete URLs that we can pass to our requests.get() function to retrieve the source code for these book pages. How do we get the URLs for all The Books on the 50 pages of book results?  
 Step 3: Find the URL Pattern  
If we click on the "next" button on the bottom right of the page, we'll see a small change in the URL in our address bar.  

- The original URL is:                           https://books.toscrape.com/  
- After we click the next button once, we get:   https://books.toscrape.com/catalogue/page-2.html  
- If we click the next button again, we get:     https://books.toscrape.com/catalogue/page-3.html  

Hopefully, you can see the pattern here. After the first page, we have an additional "catalogue/page-X.html" part added to the URL. In fact, if we add this part to the first URL, we should get the first page if we change it to "page-1."  

Try it out: https://books.toscrape.com/catalogue/page-1.html  

If we are visiting multiple pages, it is a requirement that the URL changes as well. If we click the "next" button and we see that the URL does **not** change, we would probably need to use another web scraping tool called Selenium which is able to scrape dynamic web elements.  

Our goal now is to generate a URL for **every results page**. Since we have identified the pattern, and we can see how many pages there are in total at the bottom of the screen, this should be a simple operation using list comprehension.  
```
results_pages = [f'https://books.toscrape.com/catalogue/page-{i}.html' for i in range(1,51)]
print(results_pages[:5])
```
Now that we have all of the URLs for the different results pages, and we have the code to find all the book page URLs for any given page, let's now move on to getting the data from each book page.  

Let's create another BeautifulSoup object using the source code from a book page. We can use the first book on the first page as an example for testing.  
```
response = requests.get('https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html',
                        headers = headers)
text = BeautifulSoup(response.text, 'html.parser')
```


Remember, the fields we are interested in scraping are:  

- title
- price
- average rating
- genre
- UPC
- how many books available
- whether the book is in stock  

```
# Book title
title = text.find('h1').string
print(title)

# The above only works if this is the first or only h1 tag 
# in the entire source code. We can be safer by including
# the parent div tag with it's identifying attribute.
title = text.find('div', attrs = {'class': 'col-sm-6 product_main'}).find('h1').string
print(title)
```
```
# Book price
price_in_pounds = text.find('p', attrs = {'class':'price_color'}).string
print(price_in_pounds)

# Note that there is a strange character before the pounds symbol.
# We will discuss how to handle this later.
```
```
# Average rating
# This one is a little tricky. Where can we find the
# number of stars for the average rating?

# What is this anonymous function doing?
avg_rating_tag = text.find(lambda tag: 'star-rating' in tag.get('class') if tag.get('class') else False)
avg_rating = avg_rating_tag.get('class')
print(avg_rating)

avg_rating = avg_rating[1]
print(avg_rating)

# Note that this is still in string format. We will handle this later.
```
```
# Genre
# Where is the genre of the book located on the page?

li_tag = text.find('ul', attrs = {'class':'breadcrumb'}).find_all('li')[2]
genre = li_tag.find('a').string
print(genre)
```
```
# UPC
# What is the benefit of scraping the UPC code?

# Why is there no tbody tag between the 'table' and 'tr' tags?
# chrome will sometimes add a tbody tag in the inspect view for tables, it is not actually in the source code
tr_tag = text.find('table', attrs = {'class':'table table-striped'}).find_all('tr')[0]
upc = tr_tag.find('td').string
print(upc)
```
```
# How many books are available?
# There are two places where this information is available,
# the tag is easier to indetify in the area by the book title.

num_books_available = text.find('p', attrs = {'class':'instock availability'}).get_text()
print(num_books_available)
```
_Step 5: Bringing the Code Together_  

We now have all of the code necessary to scrape all the book page information for every book listed on every results page. Let's think about how our code should traverse these different levels.  

1. Generate a list of results page URLs.  
2. Create an empty list to hold the book page URLs.  
3. Get the source code for every results page and scrape all of the book page URLs, add these URLs to the URL list (after adding the domain to each URL).  
4. After we have all the book page URLs, get the source code for each book page and scrape the relevant information.  
5. Store the information in an appropriate data structure.  
6. We either save these data structures in a list, or we can write the book information to a CSV file (or use a number of other options for persisting the data).  

```
from bs4 import BeautifulSoup
import requests

headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36'
            }

# Generate the results page URLs
results_pages = [f'https://books.toscrape.com/catalogue/page-{i}.html' for i in range(1,51)]

# Create empty list to hold book page URLs
book_page_urls = []

# For each results page, scrape the URLs for each book page
for url in results_pages:
    response = requests.get(url, headers=headers)
    text = BeautifulSoup(response.text, 'html.parser')
    
    if response.status_code != 200:
        raise Exception(f'The status code is not 200! It is {response.status_code}.')

    # Get the book page URLs and add the domain, then add to book page URL list
    book_divs = text.find_all('div', attrs={'class': 'image_container'})
    book_urls = [tag.find('a').get('href') for tag in book_divs]
    complete_book_urls = [f'https://books.toscrape.com/catalogue/{end_part}' for end_part in book_urls]
    # What is the difference between append and extend?
    book_page_urls.extend(complete_book_urls)
```


**Note**: There is another way to approach this process. We could scrape the book page URLs on one results page and then visit every book page to get the book information before moving on to the next results page. Either way is fine, but I prefer to get all the links first and then visit them later.  



Let's now visit each book page and use the code that we tested earlier to get all of the book information.

```
# Create an empty list to hold our book information
book_list = []

# Let's just get the first 100 so this doesn't take very long
for url in book_page_urls[:100]:
    # We'll store our book information in dicitonaries so
    # we should create a new dict for every iteration
    book_dict = {}
    
    response = requests.get(url, headers = headers)
    text = BeautifulSoup(response.text, 'html.parser')
    
    if response.status_code != 200:
        raise Exception(f'The status code is not 200! It is {response.status_code}.')
    
    # Get title
    title = text.find('div', attrs = {'class': 'col-sm-6 product_main'}).find('h1').string
    # Get price
    price_in_pounds = text.find('p', attrs = {'class':'price_color'}).string
    # Get average rating
    avg_rating_tag = text.find(lambda tag: 'star-rating' in tag.get('class') if tag.get('class') else False)
    avg_rating = avg_rating_tag.get('class')[1]
    # Get genre
    li_tag = text.find('ul', attrs={'class':'breadcrumb'}).find_all('li')[2]
    genre = li_tag.find('a').string
    # Get UPC
    tr_tag = text.find('table', attrs = {'class':'table table-striped'}).find_all('tr')[0]
    upc = tr_tag.find('td').string
    # Get number of books available
    num_books_available = text.find('p', attrs = {'class':'instock availability'}).get_text()
    
    # Store info in the dictionary
    book_dict['title'] = title
    book_dict['price_in_pounds'] = price_in_pounds
    book_dict['avg_rating'] = avg_rating
    book_dict['genre'] = genre
    book_dict['upc'] = upc
    book_dict['num_books_available'] = num_books_available
    
    # Add dictionary to list
    book_list.append(book_dict)
book_list[:5]
```
_Step 6: Persist the Data_  
Now that we have all of our book information, we need to decide on a way to save our data. There are a few different ways we can save this data:  

1. Save to CSV  
2. Save to JSON  
3. Save to pickle  

There are advantages and disadvantages for each format. Let's talk about them.  

_CSV_  
Saving data as a CSV file is probably the most common strategy. CSV (Comma Separated Value) files are a very standard file format (think Excel spreadsheet). We can even load them directly into a pandas DataFrame.  

We can use the `csv` module to help us save the data to CSV format. Here is the [documentation](https://docs.python.org/3/library/csv.html).  
```
import csv

# Create a new CSV file
with open('books.csv', 'w', encoding = 'utf-8', newline='') as csvfile:
    # Create the CSV writer object
    book_writer = csv.writer(csvfile)
    # Write the initial header row
    book_writer.writerow(['title', 'price_in_pounds', 'avg_rating', 'genre', 'upc', 'num_books_available'])
    
    # Iterate over the list of dicts and write the values to CSV
    for book_dict in book_list:
        book_writer.writerow(book_dict.values())
```
_JSON_
JSON (JavaScript Object Notation) is another file format we can use. You mostly encounter JSON data when working with JavaScript or retrieving data from an API. JSON files look like a list of dictionaries. Often these dictionaries will have nested dictionaries as values. It's good to know how to work with this file format. Here is the [documentation](https://docs.python.org/3/library/json.html).  

```
import json

# This will create a string version of the JSON
# Note the change in encoding for the pound symbol
json.dumps(book_list)

# This will save the JSON to a file
with open('books.json', 'w', encoding = 'utf-8') as jsonfile:
    json.dump(book_list, jsonfile, indent=4)
    
# To load the JSON back, use the json.load() function
with open('books.json', 'r', encoding = 'utf-8') as jsonfile:
    loaded_books = json.load(jsonfile)
```
_Pickle_
Pickle is a way of saving any type of Python object to a file. We can then load this file back into an environment to regain access to the exact same object (in the same state). This is very useful when working with objects that took a long time to create (like a trained machine learning model) or when saving objects in Python that aren't as obvious to convert into another format. Here is the [documentation](https://docs.python.org/3/library/pickle.html).  
```
import pickle

# This will save the object as a pickle
# Note the wb mode here
with open('books.pickle', 'wb') as picklefile:
    pickle.dump(book_list, picklefile)

# This will load the pickle file
# Note the rb mode here
with open('books.pickle', 'rb') as picklefile:
    loaded_books = pickle.load(picklefile)
```


## Arrays  
The type ndarray is flexible because it supports a great variety of primitive data types: subject to the homogeneity condition, which means every element in ndarray has the same type.  

```{python}
import numpy as np
nested_lst1 = [[-1,2,1,2],[5,-6,5,6],[7,8,-7,8]]
nested_lst2 = [[1,2,1,2],[5,6,5,6],[7,8,7,8]]
multi_ary1 = np.array(nested_lst1)
multi_ary2 = np.array(nested_lst2)
higher_dim = np.array([multi_ary1, multi_ary2])
higher_dim
```
### Array Functions
```{python}
np.arange(10)
np.arange(2,10) #start, #stop
np.arange(2,10,3) #start, #stop, #step
np.linspace(0,10, 51) #(start, end, no of elements)
np.ones((3,2)) #(array of ones of dimension 3x2)
np.zeros((4,3,2)) #array of zeroes of dimension 4x3x2)
high_x1 = np.array([[1,2,3],[4,5,6]])
high_x1.shape
x = np.arange(8)
x.reshape([2,4], order='F') #reshapes array to 2x4 fills by columns
x.astype(float) # change datatype of array elements

```
## Matrix
```{python}
x = np.matrix([3,2])
print(type(x))
print(x.shape)
x
```
### Matrix Multiplication  

The type matrix is for linear algebra, in which the matrix multiplication is always **“a row times a column”**:

$$
(1,2,3) \times \left(
\begin{array}{c}
1\\
2\\
3\\
\end{array}
\right)
= (1+4+9) = 14
$$
### Identity Matrix  
```{python}
Id = np.matrix(np.eye(3))
Id
```
### Inverse Matrix

The identity matrix is analogous to the number one.  One is referred to as the multiplicative identity, since any number multiplied by one remains unchanged. A nonzero number has a multiplicative inverse, or reciprocal.  The product of a number and its multiplicative inverse is the multiplicative identity, one. 

**For real scalars:**

- nonzero number: n
- multiplicative identity: 1
- multiplicative inverse: $\frac{1}{n}$
$$n \times 1 = n$$

$$n \times \frac{1}{n}=1$$

The analogy for a square matrix is called an inverse matrix.  A nonsingular square matrix has a multiplicative inverse, or inverse matrix.  The product of a matrix and its inverse matrix (in either order) is the identity matrix. 

**For real-valued square matrices:**

- nonsingular matrix: $M$
- identity matrix: $\textbf{1}$
- inverse: $M^{-1}$
$$M \cdot \textbf{1} = M$$

$$M \cdot M^{-1}=\textbf{1}$$

$$M^{-1} \cdot M=\textbf{1}$$  

- How do you find a tuple of `x`, `y` and `z` satisfying all the equations below?
$$
\begin{eqnarray}
3x +2y -z &= 1\\
2x -2y +4z &=-2\\
-x +\frac{1}{2}y- z&= 0
\end{eqnarray}
$$

Observe that the equation can be written as:

$$
\begin{pmatrix}
3 &2  &-1 \\ 
2 &-2  &4 \\
-1&\frac{1}{2}&-1
\end{pmatrix}
\times
\begin{pmatrix}
x\\y\\z
\end{pmatrix}
=
\begin{pmatrix}
1\\-2\\0
\end{pmatrix}
$$

$$\begin{pmatrix}
x\\y\\z
\end{pmatrix}=
\begin{pmatrix}
3 &2  &-1 \\ 
2 &-2  &4 \\
-1&\frac{1}{2}&-1
\end{pmatrix}^{-1} \times
\begin{pmatrix}
1\\-2\\0
\end{pmatrix}$$  


```{python}
M = np.matrix([[3, 2, -1],[2, -2, 4],[-1, 0.5, -1]])
M2 = np.matrix([[1], [-2], [0]])
M.I * M2
```



## Classes  


_Attributes and Methods_

- We’ll go into details in a bit, but here is the syntax to define a simple class:  

```
class Classname(object):
    def __init__(self):
        initialize representation by assigning to variables

    def methodname(self, ...args...):
        define method; 
        change representation or return value or both; 
        use self.var to refer to variable var defined in init.
```

- In `__init__`, we assign the desired representation to one or more variables, so we just have to decide what their names will be.  

- Once we have this class, we can create instances of it:  

```
newobj = Classname()
```

- We invoke methods using object notation:  

```
newobj.methodname(...args...)
```
- Note that even though we defined the method using ordinary function definition syntax, we must call it using object syntax.  That is just because it is defined inside a class.  
- However, in Python, there is an attribute naming convention to denote private attributes by prefixing the attribute with one or two underscores, e.g:

```python
self._coords
self.__coords
```

* `Person` is the **class**
* `name` and `age` are each an **object attribute**
* `say` is an **object method**
```{python}
class Person():
    '''This is the documentation of the class person ... here'''
    
    def __init__(self,a_name,a_age):#constructor
        self.name=a_name
        self.age=a_age
        
    def intro(self):
        print("My name is",self.name,"and I am",self.age,"years old")

```

### _Special Name method_
use the `__str__` special method    
and the `__add__` special method  
second arg in an attribute definition is ussually labeled as `other`   


```{python}
class Vector(object):
    def __init__(self, lis):
        self.coords = lis


    def length(self):
        return sum([x**2 for x in self.coords])**.5
    
    def __str__(self):
        return 'Vector' + str(self.coords)
    def __add__(self, other):
        return Vector(list(map(lambda x, y: x+y, self.coords, other.coords)))
    
# Then we print the Vector object:
vec_1 = Vector([1,2,3])
print(vec_1)
```

#### _Exercise_  
- Now our Vector class looks like this:  

```
class Vector(object):
    def __init__(self, lis):
        self.coords = lis

    def length(self):
        return sum([x**2 for x in self.coords])**.5

    def __add__(self, other):
        return Vector(map(lambda x, y: x+y,
                          self.coords, other.coords))

    def __str__(self):
        return 'Vector'+str(self.coords)

```

- Add two more methods to the class:  
`__eq__(vec)`: returns `True` if this vector equals `vec`.
 - `u == v` calls `u.__eq__(v)`.  
- `__mul__(vec)`: returns the dot product of this vector and `vec`. The dot product is defined by: (`x`, `y`, …) `*` (`x’`, `y’`, …) = `xx’ + yy’ +` …   
 - `u * v` calls `u.__mul__(v)`  
 
- Then evaluate the following expressions ( equality and $cos(\theta)$):  

```{python}
class Vector(object):
    def __init__(self, lis):
        self.coords = lis

    def length(self):
        return sum([x**2 for x in self.coords])**.5

    def __add__(self, other):
        return Vector(list(map(lambda x, y: x+y, self.coords, other.coords)))

    def __str__(self):
        return 'Vector'+str(self.coords)
    
    def __eq__(self, other):
        return list(self.coords) == list(other.coords)
        
    
    def __mul__(self, other):
        return sum(list(map(lambda x,y: x*y, self.coords, other.coords)))
u = Vector([1,1,0])
v = Vector([0,1,1])
print(u == v)                      
print((u*v) / (u.length()*v.length()))
```

### _Inhereitance_
inherited classes do not need an init statement

```{python}
class Book(object):
    def __init__(self, name, author = None):
        self.name = name
        self.author = author
    
    def __str__(self):
        return '<%s> by %s' % (self.name, self.author)
class EBook(Book):
    def __init__(self, name, author = None):
        Book.__init__(self, name, author)
```
 create a mutating method  
```{python}
class Book(object):
    def __init__(self, name, author = None):
        self.name = name
        self.author = author
    def __str__(self):
        return '<%s> by %s' %(self.name, self.author)
    def rename(self, newname):
        if not isinstance(newname, str):
            raise TypeError('please enter a valid str value for new name')
        self.name = newname

book_1 = Book('The little SAS book', 'Lora D. Delwiche')
print("The name of book_1 is originally %s" % book_1)
book_1.rename('The SAS book')
print("The name of book_1 is now %s" % book_1)
```
### _Class Method_

uses the class itself as an argument in a method to return some object  
```{python}
class Date(object):

    def __init__(self, day = 0, month = 0, year = 0):
        self.day = day
        self.month = month
        self.year = year
        
    
    @classmethod
    def from_string(cls, date_as_string):
        '''
        This function takes a string as input and returns a Date object.
        The input string needs to follow the format of 'dd-mm-yyyy'
        '''
        day, month, year = list(map(int, date_as_string.split('-')))
        date1 = cls(day, month, year)
        return date1
        
# usage
date2 = Date.from_string('23-08-1990')
date2.year
```
- We've implemented date string parsing in one place and it's reusable now.  
- @classmethod is a special syntax sugar called [decorator](https://realpython.com/blog/python/primer-on-python-decorators/) in Python.   
- Decorator takes a function as an input and returns the modified function as the output. i.e. convert the `from_string` function to a class method.  
- cls is an object that holds **class itself**, not an instance of the class. It's pretty cool because if we inherit our Date class, all children will have from_string defined also.  


## Regular Expressions
https://learnbyexample.github.io/python-regex-cheatsheet/

### _Meta Characters_  
`.^$*+?{}[]\|()`  


### _Import and basic methods_  
```
import re
raw_string = 'Hi, how are you today?, Hi'
re.search('Hi', raw_string)
print(s.start()) # the starting position of of the matched string
print(s.end())   # the ending position index of the matched string
print(s.span())  # a tuple containing the (start, end) positions of the matched string
print(s.group()) # the matched string
# split by common seperators
print(re.split(re.split('[\n ,.-]+', s))) #Split the string into a list by the pattern. 
# find all letters
print(re.findall('[a-zA-Z]+', s)) # Find all substrings where the pattern matches, and return them as a list.
```

### _dot_

`.` refers to any single character  
`a.` matches any 2 characters that start with a  
```
print(re.search('a.', 'aa') != None)
print(re.search('a.', 'ab') != None)
print(re.search('a.', 'a1') != None)
print(re.search('a.b', 'a+b') != None)
print(re.search('a.b', 'a+x+b') != None)
print(re.search('../../201.', 'From 06/01/2015') != None)
s = re.search('(..)/(..)/(201.)', 'From 06/01/2015')
print(s.group(1))
```
### _Question mark, plus, asterisk, and {}_

\? matches the preceding expression either once or zero times.  

\+ matches the preceding expression character at least once.  

\* matches the preceding expression character arbitrary times.  

\{m,n\} matches the preceding expression at least m times and at most n times.  

For example, ba\?b matches bab and bb.  

### _caret / dollar sign_  

^ refers to the beginning of a text, while $ refers to the ending of a text.  

For example, ^a matches any text that begins with character a.  

a$ matches any text ending with character a.  

### _bracket_


\[\] is used to specify a set of characters that you wish to match. For example, [123abc] will match any of the characters 1, 2, 3, a, b, or c ; this is the same as [1-3a-c], which uses a range to express the same set of characters. Further more [a-z] matches all lower letters, while [0-9] matches all numbers.  
Special characters lose their special meaning inside sets. For example, [(+\*)] will match any of the literal characters '(', '+', '*', or ')'.  
Characters that are not within a range can be matched by complementing the set. If the first character of the set is '^', all the characters that are not in the set will be matched.  

### _vertical bar_


| is a logical operator. For examples, a|b matches a or b, which is similar to [ab]. abc|123 matches abc or 123, while [abc123] matches any single characters in a, b, c, 1, 2, 3.  

### _Special sequence in regular expression_
There are some special sequences that have special meaning in regular expression.  

\\d: Matches any decimal digit; this is equivalent to the class [0-9].  

\\D: Matches any non-digit character; this is equivalent to the class [^0-9].  

\\w: Matches any alphanumeric character; this is equivalent to the class [a-zA-Z0-9_].  

\\W: Matches any non-alphanumeric character; this is equivalent to the class [^a-zA-Z0-9_].  

\\s: Matches any whitespace character; this is equivalent to the class [ \t\n\r\f\v].  

\\S: Matches any non-whitespace character; this is equivalent to the class [^ \t\n\r\f\v].  

## Files  

### _Read file as text_
```
!type <name of file>
```

### _pickle files_


### Opening Files
```{python, eval=FALSE}
f = open('fooz.txt', 'r') 
f.read()
f.close()
# reads entire file as a string
# 'r' opens files for reading
# 'a' opens file for appending
# 'w' opens file for overwriting
# 'r+' read and append
```
### Reading Files
```{python, eval = FALSE}
f = open('fooz.txt', 'r')
lines=f.readlines()
print(lines)
f.close()
# reads each line as list
```
### Iterating Files  
```{python, eval = FALSE}
f = open('fooz.txt', 'r')
for i in f:
    print(i)
f.close()
```
```
# lets capitalize everything in our file
text = ''.join(list(map(lamba s: s.upper(), lines)))
print(text)
```
Write a function to strip the new line characters out of a file
```
def e_to_a(filename):
    f = open(filename, 'r')
    lines = f.readlines()
    lines = list(map(lambda x: x.strip(), lines))
    f.close()
    return lines
```
### Writing files
```{python, eval = FALSE}
f.write('this is some text.\nThis is another line.\n')
f.write('oh snap, more lines.\nIt\'s a line.\n')
f.close()
```

## Random Sampling  

The `numpy.random` submodule provides random-variable generator. Some are listed below:

- `randn(d0, d1, ..., dn)`: Each entry is from the “standard normal” distribution.

- `rand(d0, d1, ..., dn)`: Random array with a given shape where each element is from Uniform [0, 1].

- `randint(low, high, size)`: Random integers ranging from low (inclusive) to high (exclusive).

- `random_integers(low, high, size)`: Random integers between low and high, both inclusive.

- `random_sample(size)`: Random floats in the half-open interval [0.0, 1.0).

- `choice(a[, size, replace, p])`: Generates a random sample from a given 1-D array. By default, `replace=True`.  
```{python}
import numpy as np
np.random.randn(10)
```
## Scipy
```{python, eval=FALSE}
import numpy as np
from scipy import stats

from sklearn import datasets
iris_raw = datasets.load_iris()
```
```{python, eval = FALSE}
iris = iris_raw.data
iris[0:8,:]
sepal_len = iris[:,0] # gets first column, sepal length
sepal_wid = iris[:,1] # gets 2nd column, sepal width
petal_len = iris[:,2] # gets column 3, petal length

```

## Statistical Functions  
```{python, eval=FALSE}
stats.describe(sepal_len)
np.unique(species, return_counts = True) 
stats.ttest_1samp(petal_len, 10) # 1 sample t test
stats.ttest_ind(sepal_len, petal_len) #2 sample t test
stats.f_oneway(sepal_len, sepal_wid, petal_len) # ANOVA

```
## Distributions

```{python, eval=FALSE}
my_binom = stats.binom(6, 0.5) # binomial distribution
my_binom.rvs(10) # random sampling
my_binom.pmf(3) # returns likelyhood
my_norm = stats.norm(3, 1) # normal distribution with mean = 3, stdev = 1
my_norm.cdf(4) #culmulative density object
my_norm.pdf(4)) # probability density function

```
## PANDAS

### Series
```{python}
import pandas as pd
obj = pd.Series(['a', 'b', 'c', 'd'])
obj

```
#### Slicing
```{python}
obj[0]
obj.index
obj.values

```
#### Convert Dictionary to series
```{python}
dict_ = {1: 'a', 2: 'b', 3: 'c', 4: 'd'}
obj3 = pd.Series(dict_)
obj3
obj3.to_dict() # and back to dictionary

```
### Dataframes

#### Creating a dataframe  
```{python}
# From Dictionary
import pandas as pd
data = {'commodity': ['Gold', 'Gold', 'Silver', 'Silver'],
        'year': [2013, 2014, 2014, 2015],
        'production_Moz': [107.6, 109.7, 868.3, 886.7]} 


df = pd.DataFrame(data)
df
# from nested list
df_2=pd.DataFrame([[107.6, 'Gold', 2013],
                   [109.7, 'Gold', 2014],
                   [868.3, 'Silver', 2014],
                   [886.7, 'Silver', 2015]], 
                    columns=['production_Moz','commodity','year'])
df_2
```
can also create a dataframe with a nested list  
```{python}
df_2 = pd.DataFrame([[107.6, 'Gold', 2013],
                   [109.7, 'Gold', 2014],
                   [868.3, 'Silver', 2014],
                   [886.7, 'Silver', 2015]], 
                    columns = ['production_Moz','commodity','year'])
df_2
```

#### DF Methods
```
df.values
df.index
df=df.set_index('commodity') # sets index to commodity column
df=df.reset_index() # has a drop argument, defaults to false

df.columns
df.index
df.tolist() # creates a list of column names
# can appply the string sub module to use string methods
#df.columns.str.replace()

```

#### DF slicing
```{python}
# First index is column, second index is a row
# how to get columns
df.commodity
df['commodity']
df.iloc[1]
df.loc[:,'commodity'] #row : Col
df[['commodity']] # returns a df
df['commodity'][0] # returns comodity column row 0
df[['commodity', 'year']]
df.loc[df['commodity'] == 'Gold', :]
df.loc[:, df.loc[0] == '2013']
#df.loc[row,col]
# returns all rows for the columns in which row 'one' is a value.
# df1.loc[:, df1.loc['One'] ==  #value]
```
#### DF Functions
```{python, eval = FALSE}
df.sort_values('value') # column to sort on
df.concat(df1, df2) #always combines on index
pd.merge() # df1, df2, how(left, inner), on(column to merge on)
# if cols dont have the same name  use 'left_on' and 'right_on' to indicate how to perform the merge.
# df.rename({'oldname':'newname'}, axis =1)

```
#### _Data Merging_
```{python}
df1 = pd.DataFrame(np.arange(9).reshape((3, 3)), 
                   columns = ['a', 'b', 'c'],
                   index = ['one', 'two', 'three'])
df2 = pd.DataFrame(np.arange(6).reshape((3, 2)), 
                   columns = ['d','e'],
                   index = ['three', 'two','one'])
print(df1)
print(df2)
```
Since the two data frames have the same number of rows, it is natural to combine them "horizontally".  
Note the concatenation takes place on the name of the index and not the order.  
Merges based on index  
```{python}
pd.concat([df1, df2], axis = 1, sort = False)
```
hstack will merge without matching indices  
```{python}
np.hstack((df1.values, df2.values))
```
example if indices dont match and you use concat, populates with Nan values  

```{python}
df1 = pd.DataFrame(np.arange(9).reshape((3, 3)), 
                   columns = ['a', 'b', 'c'],
                   index = ['One', 'two', 'three'])
df2 = pd.DataFrame(np.arange(6).reshape((3, 2)), 
                   columns = ['d','e'],
                   index = ['three', 'two','one'])
print(df1,'\n\n',df2)
print(pd.concat([df1, df2], axis = 1, sort = False))
```
can use an inner join  
```{python}
pd.concat([df1, df2], axis = 1, join = 'inner')
```

#### _Apply_  
`apply` applies a function on 1D arrays of columns and rows  
```
df1.apply(lambda x: max(x), axis = 0) # 0 stands for apply to each column
```
will return max value for each column  

If you just want to apply the function to a single column, you can extract that specific series first and then call the map() method just like the map operator in Python.  
```
df1.a.map(lambda x: x+1)
```
### _additional techniques_
how to group columns with multiple substrings in a cell  
```
# strings seperated by |
df_genre.genres = df_genre.genres.apply(lambda x: x.split('|'))
# turns genre column into a list of strings
index=0
# save [index, genre] in a nested list
list_ = []
for item in df_genre.genres:
    list_.extend(map(lambda x: [index, x], item))
    index += 1
genre = pd.DataFrame(list_, columns = ['index', 'genres'])
genre.head() 
#gives a dataframe 
```


#### Group
```{python, eval=FALSE}
df.groupby('colname')
# groups are iterable
for item in group:
  print item
# make a grouypby dictionary
group_dict = dict(iter(group))
group.agg(['count', 'mean', 'min', 'max', 'sum', 'std'])
```


#### Read from file
```{python, eval = FALSE}
df=pd.read_csv('foo.csv')
df

```
#### DF Null values
```{python, eval = FALSE}
df.isnull() # returns t/f dataframe
np.sum(df.isnull()) # sums nulls per column
one      2
two      2
three    2
four     1
dtype: int64
np.sum(df_miss.isnull(), axis=1) # sums nulls per row
df.dropna(axis=0, how='any') # drops rows with NA values
df.fillna(0) # fills NA values
df['one'].fillna(df_miss['one'].mean()) # fills all NAs in 'one' column with the mean
df.interpolate() # fills NA values with a linear regression of surrounding values
# create a boolean mask for missing values
# mask = df_miss.isnull().any(axis = 1)
# df_miss.loc[~mask,:] will return only non NAN values the tilda operator is negation
```





## MatplotLib
```{python, eval = FALSE}
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
plt.style.use('ggplot')
x=[5,5,5,10,10,30,30,20,25,40]
plt.hist(x)
plt.show()
values=[1628701 ,2582830, 1432132, 476179 , 2278906]
labels=['Manhattan','Brooklyn','Bronx','Staten Island', 'Queens']
plt.pie(values,labels=labels)
plt.boxplot(x)
x=[7,8,9,11]
y=[9,4,6,7]
plt.bar(x,y);
plt.barh(x,y);
plt.scatter(x,y);

```

### _Outliers_
to remove outliers more than n std deviations out  
`scatter_df = scatter_df.loc[scatter_df.apply(lambda x: np.abs(x - x.mean()) / x.std() < n).all(axis = 1)]`


### _Histogram_
```{python}
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
df = pd.read_csv('https://s3.amazonaws.com/nycdsabt01/movie_metadata.csv')
plt.hist(df['imdb_score'], bins = 20, color = "#5ee3ff")

```
### _Scatterplot_
```{python}
plt.scatter(df['budget'], df['gross'])
plt.xlabel('Budget')
plt.ylabel('Gross Income')

```
### _Barplot_
barplot with a groupby  
```{python}
plt.figure(figsize = (12,6))
df.groupby('country')['imdb_score'].median().sort_values(ascending=False).plot.bar(color = 'b')
```

### Plotting Functions
```{python, eval = FALSE}

X=np.linspace(0,4*3.14,101)
Y=np.sin(X)
plt.plot(X,Y,'.')
```
### Plotting Features
```{python, eval = FALSE}
plt.figure(figsize=(12,6)) #figsize must be first declaration
plt.plot(x,y,'g.-',markersize=20, linewidth=4,alpha=0.4,label='data1')
plt.plot(x,y2,'.--',color='red',markersize=10,alpha=0.7,linewidth=0.3,label='data2')
plt.legend(loc=1)
plt.title('Example Plot')
plt.xlabel('horizontal axis')
plt.ylabel('vertical axis')
plt.xlim(6,12)
plt.ylim(0,10)
plt.xticks([6,9,12])
plt.yticks([0,4,8])
plt.text(10,2,'some text',color='blue',size=14)
plt.show()
```

## Seaborn
```{python, eval = FALSE}
import seaborn as sns
titanic=sns.load_dataset('titanic')
```
```{python, eval = FALSE}

sns.countplot(x="deck", data=titanic);
plt.hist(titanic['deck'].dropna());
sns.stripplot(x="sex",y="age",data=titanic)
sns.swarmplot(x="sex",y="age",data=titanic)
sns.barplot(x="sex",y="survived", data=titanic)
sns.barplot(x="sex",y="survived", hue='class', data=titanic)
```



# R  

## Markdown  

### Formatting  
For basic formatting for your output HTML document    
(how to update your YAML Preamble):  

https://bookdown.org/yihui/rmarkdown/html-document.html  


### Themes:  

https://www.datadreaming.org/post/r-markdown-theme-gallery/  


### Code Chunk   

https://yihui.org/knitr/options/  


### Advanced Themes:  

https://cran.r-project.org/web/packages/rmdformats/readme/README.html 


### LaTex:  

https://joshua.smcvt.edu/undergradmath/undergradmath.pdf  


### HTML   

colors, fonts, etc... (most tags will not work if placed around codechunks, or will not work as expected)  

https://daringfireball.net/projects/markdown/syntax  

## Functions
```{r}
cost_per_person <- function(people, bill) {
  tax = bill * 0.07
  tip = bill * 0.18
  total = bill + tax + tip
  costPP = total / people
  return(costPP)
}
```
```{r}
cost_per_person(5, 221.78)
cost_per_person(4, 221.78)
```
### Default Arguments  
```{r}
xyz = function(x=1, y, z=1) {
  return(x * 100 + y * 10 + z)
}
```

### Built In Functions
```{r}
set.seed(0) # For reproducible results
x = rnorm(1000, mean=2) # Random sample from a normal distribution

mean(x) # mean of x
median(x) # median of x
var(x) # variance of x
sd(x) # standard deviation of x
quantile(x, c(0.25, 0.50, 0.75)) # quantiles of x
sum(x) # sum of x
```

## Working Directory
```{r}
getwd()
```
```{r}
#setwd("C:/Users/cmmaf/Desktop/RDA-50/1/Lecture")
#setwd("C:/Users/cmmaf/Desktop/RDA-50")
```

## Reading Files
```{r}
#full_path = "C:/Users/cmmaf/Desktop/RDA-50/1/Lecture/data/CPS1988.csv"
#CPS1988 = read.csv(full_path, header=TRUE)

#relative_path = "data/CPS1988.csv"
#CPS1988 = read.csv(relative_path, header=TRUE)
library(AER)
data("CPS1988")

dim(CPS1988)
```

## Data Frames

### Useful Methods
```{r}

head(CPS1988)
str(CPS1988, vec.len=5)
head(CPS1988$region)
```

### Slicing Data Frames
```{r}
str(CPS1988, vec.len=1)
```
```{r}
CPS1988$wage[1:8]
```
```{r}
CPS1988[["wage"]][1:8]
```
```{r}
CPS1988["wage"]
```

```{r}
CPS1988[c("wage", "education")]
```

```{r}
# Use $ to get individual columns out as vectors
CPS1988$wage[1:6]
CPS1988$education[1:6]
```

```{r}
# We can use brackets as well, however since df's have 2 dimensions df[ROWS, COLUMNS]

# Returns a df, first 10 rows and columns 2 and 4
CPS1988[1:10, c(2,4)]
```

```{r}
CPS1988[1:10, c('education', 'ethnicity')]
```





```{r}
# All rows but for the educ and exper columns
CPS1988[c('education', 'experience')]
#CPS1988[ , c('education', 'experience')]
```

```{r}
# If you get only one column, it will be a vector
class(CPS1988[, 1])
class(CPS1988[, 1:2])
```
```{r}
CPS1988["wage"]
```

```{r}
CPS1988[1]
```

## Lists
```{r}
myVec = 1:10
```
```{r}
myMat = matrix(1:12, ncol=3)
```

```{r}
myDf = CPS1988[1:10, ]
```

```{r}
myList = list(myVec, myMat, myDf)
myList
namedList = list(A=myVec, B=myMat, C=myDf)
namedList$D = pi

namedList['E'] = exp(1)

namedList
```

## Control Flow

### IF  
```{r}
num = 5
# Note: %% is the Modulo (remainder) operation
if (num %% 2 != 0) {
  cat(num, 'is odd')
}
```
```{r}
num = 5

if (num %% 2 != 0) {
  cat(num, 'is odd')
  # more commands
} else {
  cat(num, 'is even')
  # more commands
}
```
```{r}
set.seed(0)
age = sample(0:100, 20, replace=TRUE)
age
res = ifelse(age > 70, 
             'old', 
             ifelse(age <= 30, 
                    'young', 
                    'mid'))
res
```
### FOR
```{r, eval=FALSE}
library(readr)
sign_data = read.csv("TimesSquareSignage.csv", header=TRUE)
obs = nrow(sign_data)
for (i in 1:obs) {
  if (is.na(sign_data$Width[i])) {
    cat('WARNING: Missing width for sign no.', i, '\n')
  }
}
```
### While
```{r, eval = FALSE}
i = 1
while (i <= obs) {
  if (is.na(sign_data$Width[i])) {
    cat('WARNING: Missing width for sign no.', i, '\n')
  }
  i = i + 1
}
```
## Dplyr

### Tibble
```{r}
library(dplyr)
births_df = read.csv("C:/Users/jmeis/RDA_054/Lecture 2/data/births.csv", stringsAsFactors=FALSE)
bnames_df = read.csv("C:/Users/jmeis/RDA_054/Lecture 2/data/bnames.csv", stringsAsFactors=FALSE)
births = as_tibble(births_df)
bnames = as_tibble(bnames_df)
```
### Select, Filter, Arrange
```{r}
bnames %>%
  select( year, name, prop) %>%
  filter( name == 'Justin') %>%
  arrange(desc(prop)) %>%
  head(2)
```
### Mutate, Transmute, Summarise
```{r}
bnames %>%
  mutate(., newCol = year *2) %>%
  transmute(newCol = newCol/2) %>%
  summarise(sum = sum(newCol/n()))
```
### Joins
```{r}
x = data.frame(
  name = c("John", "Paul", "George", "Ringo", "Stuart", "Pete"),
  instrument = c("guitar","bass","guitar","drums","bass","drums"))
y = data.frame(
  name = c("John", "Paul", "George", "Ringo", "Brian"),
  band = c(TRUE, TRUE, TRUE, TRUE, FALSE))
left_join(x, y, by = "name")
right_join(x, y, by = "name")
inner_join(x, y, by = "name")
full_join(x, y, by="name")
semi_join(x, y, by = "name")
anti_join(x, y, by = "name")
```
### Group_by

```{r}
totals = bnames %>%
  group_by(name) %>%
  summarise(total = n())

head(totals)
```



## Shiny

### Links to resources: 
HTML Tags
https://shiny.rstudio.com/articles/tag-glossary.html
Layout Guide
https://shiny.rstudio.com/articles/layout-guide.html
Functions
https://shiny.rstudio.com/reference/shiny/latest/
Widgets
https://shiny.rstudio.com/gallery/widget-gallery.html

### Basic Layout (ui.r)
```{r, eval=FALSE}
fluidPage(
    titlePanel(...),
    sidebarLayout(
      sidebarPanel(...),
      mainPanel(...)
)
)
```
```{r, eval=FALSE}
library(shiny)
library(lubridate)

# Define UI for application that draws a histogram

fluidPage(
  titlePanel("NYC Flights 2014"),
  sidebarLayout(
    sidebarPanel(
     
      selectizeInput(inputId = "origin",
                    label = "Departure airport",
                     choices = unique(flights$origin)),
      selectizeInput(inputId = "dest",
                     label = "Arrival airport",
                     choices = unique(flights$dest)),
      selectizeInput(inputId = "month",
                     label = "Month",
                     choices = unique(flights$month)
    ),
    mainPanel(tabsetPanel(
      tabPanel('Number of Flights', plotOutput("count")),
      tabPanel('Average Delay', plotOutput("delay"))
    ))
  )
)
```


### Basic Server (server.r)
```{r, eval=FALSE}
function(input, output) {
}
```
```{r, eval=FALSE}
library(shiny)
library(dplyr)
library(ggplot2)
library(tidyverse)

function(input, output) {
  output$count <- renderPlot(
    flights %>%
      filter(origin == input$origin & dest == input$dest & month == input$month) %>%
      group_by(carrier) %>%
      count() %>%
      ggplot(aes(x = carrier, y = n)) +
      geom_col(fill = "lightblue") +
      ggtitle("Number of flights"))
  output$delay <-renderPlot(
    flights %>%
      filter(origin == input$origin & dest == input$dest & month == input$month) %>%
      group_by(carrier) %>%
      summarise(mean_arr = mean(arr_delay), mean_del = mean(dep_delay)) %>%
      gather(key = metric, value = delay, mean_arr, mean_del)  %>%
      ggplot(aes(x = carrier, y = delay, fill = metric )) +
      geom_col(position = "dodge2") +
      ggtitle('Average Delays')
      
  )
  
  
}
```
### Global .r
```{r, eval =FALSE}
#for above example
library(data.table)
flights <- fread(file = "./flights14.csv")

```
# HTML  

## Workflow
Start new document index.html with !DOCTYPE

## Parts of HTML Document  
\<title\> \<\/title\>
\<head\> \<\/head\>  
contains technical info about meta structure of doc  
\<body\> \<\/body\>  
content goes here 
Lorem# is number of lorem ipsum words to create

## Headers and Paragraphs and divs  
\<h1\> \<\/h1\>   
\<p\> \<\/p\>  
\<div\> \<\/div\> 

## Insert an image  
\<a href="about.html"\>About\<\/a\>

# CSS  
for external css create a style.css page  

## Inline CSS  
\<h1 style="color: olive;font-size: 3rem;"\>hello world\<\/h1\>

## Internal CSS
\<style\>
h1{  
  color:blue;  
  font-size: 3rem;  
}  
will change the apperance of all \<h1\> elments  
will will with spans, body, divs, paragraphs, etc...
\<\/style\>

## External CSS  
### Element selectors and grouping  
h1,h2{  
  color: red;  
}  
### IDs  
/#heading{  
  background:black;  
}  
\<h1 id="heading"\>lorem ipsum \<\/h1\>  

### Class Selectors 
.green{  
  color:green;  
}  
\<h3 class="green"\>I'm green\<\/h3\>  

### Universal Selector  
*{  
  background-color:ivory  
}  
Universal selector will be the top level css style, unless overwritten by subsequent styles  

### RGBA 0-1 Opacity/Transparency
\#\<tag\>{  
  background:rgba(0,0,0,.25)  
  \<(r value, g value, b value, opacity)\>  
}  

### Font size, width, height, pixels
{  
font-size: 30px;  
width: 200px;  
height: 300px;  
}  

### Percent Value Relative  
{  
width: 50%;  
height: 50%;  
}  

# SQL  

## comments  
\-\- Sytanx for single line comments  
/** multiline comment **/  

## _Commands_

### _SHOW \<DATABASES\> or SHOW \<database, or table\>;_
shows all databases on server, or shows DB or table

### _USE \<database\>_ 
will append database. to every table reference for example:  
`USE movies_db;`
is the same as   
`FROM movies_db.tables;`  

### _SELECT \<rows\>_
selects all rows  

### _FROM \<database\>_  
noun of the select querry  

### _WHERE ..._   
indicates the condition or conditions that rows must
satisfy to be selected.  
```
SELECT movie_title,
budget
FROM movies
WHERE budget > 1000000000;

```

### _LIMIT ..._  
```
SELECT column_names  
FROM tabel_names  
LIMIT \<offset\> \<count\>;  
```
### _AS ..._  
see column alias

### _CASE WHEN \<condition\> THEN \<result\> ELSE \<result\> END_ 
```
SELECT movie_title,   
CASE   
       WHEN title_year > 2014 THEN 'new' 
       WHEN title_year BETWEEN 2012 AND 2014 THEN 'new-ish'   
ELSE 'old'  
END AS movie_age  
FROM movies;  
```
### _DESCRIBE \<object\>_  
shows column names and values

### _Column Alias_
Select <column name> AS <column alias name>

##  Mathmatical Operators
\+  
\-  
\*  
/  
Round()  

## Comparison Operator  
= , equal to  
\> , Greater than  
\< , less than  
\>= , greater than or equal to  
\<= , less than or equal to  
\<\> , \!= , not equal to  

## Logical Operators
### _AND_  
Evaluates two conditions and
returns True if both are true.  

### _OR_  

Evaluates two conditions and
returns True if at least one is
true.   

### _BETWEEN...AND... _  

Tests value against an inclusive
range of values. 
```
SELECT movie_title,  
title_year BETWEEN 2010 AND 2012 AS year_range  
FROM movies;  
```
### _IN_  
Tests value against a list of
values and returns True if value
matches at least one in the list. 
```
SELECT movie_title, 
title_year IN (2010, 2012, 2014) AS year_range,  
country IN ('USA', 'UK') AS country_range  
FROM movies;  
```

### _IS NULL_  
Tests value to see if it is null.
Return True if null.  

### _NOT_   
Reverts False to True, and True
to False.    

## String Manipulation  

### _Wildcard Comparisons_  
_LIKE_ operator in combo with wildcards are used for pattern matching  
\% used to define any number of missing characters before and after a pattern  
\_ wildcard used to substitute for a single character or space  
example:  
Return True if the country name starts with a 'U' else return false  
```
SELECT country LIKE 'U%'  
FROM MOVIES;  
```
Return True if country starts with 'U' and ends with 'A' an has one or more spaces in between  
```
SELECT country LIKE 'U_A'  
FROM MOVIES;  
```
## _Functions_  
_LOWER()_, _LCASE()_ Return string in lowercase  
_UPPER()_, _UCASE()_ Return string in uppercase  
_CHAR_LENGTH()_ Return number of characters in a
string  
_LEFT(, n)_ Return the leftmost number of
characters specied by n  
_RIGHT(, n)_ Return the rightmost number of
characters specied by n  
_SUBSTR(, m, n)_
Return the number of characters
specied by n starting from the
m-th position of the string  
_LTRIM()_ Return the string with leading
spaces removed  
_RTRIM()_ Return the string with trailing
spaces removed  
_TRIM()_ Return the string with leading
and trailing spaces removed  
_REPLACE('s', 's1', 's2')_
Replaces all the occurrences of a
 within a string with a new
substring  
_COUNT_
```
SELECT count (*)   
from \<table name\>;  
```
counts all rows 
```
SELECT COUNT(column name)  
from movies;  
```
_SUM_
```
SELECT SUM(title_year IS NULL)  
FROM movies;  
```
counts number of null values in title year column  
_AVG_
```
Select AVG(title_year IS NULL)   
FROM movies;  
```
will give the ratio of null values  
_DISTINCT_  
```
SELECT COUNT(DISTINCT country)  
FROM movies;  
```
_MAX_  
Return the maximum value  
_MIN_  
Return the minimum value  
_STD_  
Return the population standard deviation    

_VARIANCE_  
Return the population variance  

_HAVING_  
used to filter according to result of aggregation 
```
SELECT country, COUNT(DISTINCT director_name)  
FROM movies  
GROUP BY country  
HAVING COUNT(DISTINCT director_name) > 5;  
```
_UNION_  
```
SELECT movie_title, title_year, director_name  
FROM movies  
WHERE title_year = 1972  
UNION  
SELECT movie_title, title_year, director_name  
FROM movies  
WHERE title_year = 1942;  
```
_UNION_ALL_  
keeps duplicate records in a union  

_JOIN_  
by default is inner_join 
```
SELECT expression [, expression ...]  
FROM table1 JOIN table2  
ON condition-involving-table1-to-table2;  
```
```
SELECT *  
FROM directors JOIN actors  
ON directors.name = actors.name; 
```
_LEFT OUTER JOIN_  
select all records from left table and only records on right table that match  
```
SELECT * FROM movies LEFT OUTER JOIN directors  
ON movies.director_name = directors.name;  
```
_FULL OUTER JOIN_  
There is no full outer join command  
```
SELECT * FROM movies LEFT OUTER JOIN directors  
ON movies.director_name = directors.name  
UNION  
SELECT * FROM movies RIGHT OUTER JOIN directors  
ON movies.director_name = directors.name;  
```
_Exclusion Join_  
Let's say we want to look at directors who are NOT actors. These will be
directors who do not fall in the actors table. 
```
SELECT * FROM directors LEFT OUTER JOIN actors  
ON directors.name = actors.name  
WHERE actors.name IS NULL;  
```
## GROUP BY  
```
SELECT country, AVG(imdb_score)  
FROM movies  
GROUP BY country;  
```
show the average imdb score for each country  
```
SELECT country, COUNT(DISTINCT director_name)  
FROM movies  
GROUP BY country;  
```
shows number of directors in each country  

WHERE key word is used before group by  
HAVING is used after group by  

### _Multiple GROUP BYs_
```
SELECT country, title_year, COUNT(*)  
FROM movies  
GROUP BY country, title_year;  
gives the number of movies in each country per year 
```
## ORDER BY  
```
SELECT country  
FROM movies  
ORDER BY country;  
```
or 
```
SELECT country, language  
FROM movies  
ORDER BY country, language DESC;  
```

## Order of Evaluation
1 FROM  
2 WHERE  
3 GROUP BY  
4 HAVING  
5 SELECT  

## Subqueries  
+ A subquery is a SQL statement that has another SQL query embedded in the WHERE or the HAVING clause.  
+ The syntax for a subquery when the embedded SQL statement is part of the WHERE condition is as follows:  
```
SELECT expressions  
FROM tables  
WHERE conditions [Comparison Operators]  
(SELECT expressions  
FROM tables  
WHERE conditions);  
```
+ [Comparison Operators] could be equality operators such as =, \>, \<, \>\=, and \<\=. It can also be a text operator such as "LIKE".  
+ The second select clause is considered as the "inner query," while the rst select clause is considered as the "outer query."  

Example: we want to find the highest avaerage rating  from greouped genres 
```
SELECT MAX(average.avg_rating)
FROM (
    SELECT AVG(imdb_score) AS avg_rating
    FROM movies
    GROUP BY genres
) AS average;
```
### _ALL_  
Compares a value to ervery value from the result table  
example: the following query returns all of the action movies that have a
higher IMDB score than the best fantasy movie:  
```
SELECT *
FROM movies
WHERE genres = 'Action'
AND imdb_score > ALL
    (SELECT imdb_score
    FROM movies
    WHERE genres = 'Fantasy');

```

### _EXISTS_  
The EXISTS operator checks if the row from the subquery matches any row in the outer query. If there’s no data matched, the EXISTS operator returns FALSE.  
The following query returns all the movies that are directed by director who are born after 01/01/1980.  
```
SELECT movie_title
FROM movies
WHERE EXISTS (SELECT *
    FROM directors
    WHERE directors.name = movies.director_name
    AND birthday > '1980-01-01')

```
## _Windows Functions_

### _RANK() OVER_
```
SELECT
    gross, RANK() OVER (ORDER BY gross)
    FROM movies
    WHERE gross IS NOT NULL;
```
### _Cutting with NTILE()_
A very common analytical method is to cut numeric values into a few categories.NTILE could help us to do so:  
```
SELECT
gross,
NTILE(5) OVER (ORDER BY gross DESC) AS tier
  FROM movies
  WHERE gross IS NOT NULL;
```
breaks into 5 teirs  

### _Cumulative Sums_
```
SELECT gross,
RANK() OVER (ORDER BY gross) AS _rank,
SUM(gross) OVER (ORDER BY gross) AS cum_sum,
AVG(gross) OVER (ORDER BY gross) AS cum_avg
FROM movies
WHERE gross IS NOT NULL;
```

### _Lag and rolling values_

```
SELECT
    gross,
  AVG(gross) OVER (ORDER BY gross) AS cum_avg,
  AVG(gross) OVER (
    ORDER BY gross
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
      ) AS moving_avg
FROM movies
WHERE gross IS NOT NULL;
```
the moving average takes the average of the current row ans the 2 previous  

```
SELECT
    gross,
  LAG(gross) OVER(ORDER BY gross) AS delay,
  gross - LAG(gross) OVER(ORDER BY gross) AS diff,
  (gross - LAG(gross) OVER(ORDER BY gross))/gross AS rate
FROM movies
WHERE gross IS NOT NULL;
```
_LAG_ function will generate the previous rows value
LAG(\<column\>, # to lag) defaults to 1

## PARTITION  
Rank facebook likes by tier
```
SELECT tier, movie_title,
    RANK() OVER
    (PARTITION BY tier ORDER BY movie_facebook_likes DESC)
FROM (
    SELECT
      movie_title, num_critic_for_reviews,
      movie_facebook_likes, budget,
      gross, NTILE(5) OVER (ORDER BY gross DESC) AS tier
FROM movies
WHERE gross IS NOT NULL
) Q;
```
## Data Manipulation  

## CREATE TABLE  
```
CREATE TABLE table_name (
column_name column_type [options],
...
)
```
example  
```
CREATE TABLE actors (
biography VARCHAR(6000),
birthday DATE DEFAULT NULL,
deathday DATE DEFAULT NULL,
gender INT DEFAULT NULL,
name VARCHAR(255),
place_of_birth VARCHAR(255),
facebook_likes INT DEFAULT NULL
);
```
for more options/flags  
https://dev.mysql.com/doc/refman/5.7/en/create-table.html  

### _INSERT_  
```
INSERT INTO table_name
(column_name_1, column_name_2, ...)
VALUES
(value_row1_col1, value_row1_col2, ...),
(value_row2_col1, value_row2_col2, ...),
...
;
```
```
INSERT INTO actors
(birthday,deathday,gender,name,place_of_birth,facebook_likes)
VALUES
("1942-08-17",NULL,0,"Roshan Seth","Patna, Bihar, India",61.0);
```

### _UPDATE_  
```
UPDATE table_name SET column_name = new_value
[WHERE where_condition];
```
set SQL into safe updates mode first
`SET SQL_SAFE_UPDATES = 0;`

```
UPDATE actors SET facebook_likes = 68
WHERE name = "Roshan Seth";
```

### _DELETE_  
```
DELETE FROM tbl_name
[WHERE where_condition];
```

### _TRUNCATE_  
to empty a table  
```
TRUNCATE TABLE table_name;
```

### _DROP_  
to fully remove a table  
```
DROP TABLE table name;
```

## Create Temporary Table
```
select
  select list
into
  # temporary table name (name must start with hashtag)
from
  table_name
where
  criteria
```

## SQL Command Line Prompt  
in command line  
`mysql -u<username(no space)> -p<password>`

## LOAD data  
from my SQL command line  
```
LOAD DATA LOCAL INFILE file_name
INTO TABLE table_name
FIELDS TERMINATED BY string_1 ENCLOSED BY string_2
LINES TERMINATED BY string_3
IGNORE int LINES
;
```

## Data Integrity  

### _Primary Key_
```
CREATE TABLE actors (
biography varchar(6000),
birthday date DEFAULT NULL,
deathday date DEFAULT NULL,
gender int DEFAULT NULL,
name varchar(255),
place_of_birth varchar(255),
facebook_likes int DEFAULT NULL,
PRIMARY KEY (name)
);
```

### _Foreign key_
```
ALTER TABLE child_table
ADD CONSTRAINT constraint_name
FOREIGN KEY index_col_name
REFERENCES parent_table(index_col_name);
```
```
ALTER TABLE movies
ADD CONSTRAINT FK_ActorMovie
FOREIGN KEY (actor_1_name) REFERENCES actors(name);
```

### _CASCADE_ or _SET NULL_
When you try to delete or change a record that is a primary or foreign key in a table must set cascade
ON DELETE CASCADE will change all child records 
ON DELETE SET NULL - will set null in all child records




## Example Exercises  
+ Find the average lost of the movies which actually lost money for each country.
```
SELECT country, AVG(gross - budget)
FROM movies
WHERE (gross - budget) < 0
GROUP BY country;  
```

+ Find the average lost of the movies for each country whose movies lost money on average.  
```
SELECT country, AVG(gross - budget)  
FROM movies  
GROUP BY country  
HAVING AVG(gross - budget) > 0;  
```
+ Show the languages and the count of the movies in which each language is spoken. Order the result by the count.  
```
select language,  
	count(*)  
from movies  
group by language  
order by count(*) desc;  
```
+ Find how many records are in each of the tables of the previous example from performing both UNION and UNION ALL on the actors and directors tables.  
```
SELECT COUNT(*) FROM (  
SELECT name, birthday FROM actors  
UNION  
SELECT name, birthday FROM directors
) AS union_table;  
```
+ Exercise: How many people are both directors and actors in the dataset?  
```
select count(*) as DirectorActors  
from actors  
join directors  
on (directors.name = actors.name  
directors.birthday = actors.birthday) and;  
\-\- to filter out null values causing incorrect matches   
(directors.birthday = actors.birthday OR  
directors.birthday is NULL AND  
actors.birthday is NULL);  
```

+ Find the number of directors who are not also in the actors table  
```
select * from directors left outer join actors  
on directors.name = actors.name  
where actors.name is null;  
```
+ find the number of actors who are not in the directors table  
```
select * from actors left outer join directors  
on actors.name = directors.name  
where directors.name is null;  
```
+ the number of people who are both directors and actors.  
```
select * from actors inner join directors  
on actors.name = directors.name  
```
+ Find all the directors who's facebook_likes are in the top 10 facebook_likes from directors table.  

```
SELECT name, facebook_likes
FROM directors
WHERE facebook_likes >= (
    SELECT facebook_likes
    FROM directors
    ORDER BY facebook_likes DESC
    LIMIT 1 OFFSET 9 -- n-1 here for the top n.
)
ORDER BY facebook_likes DESC;
```
+ Find the average facebook likes and critics reviews for each of 5 tiers of profitability of the movies DB  
```
SELECT tier,
    AVG(num_critic_for_reviews) AS avg_critics,
    AVG(movie_facebook_likes) AS avg_flikes
FROM (
    SELECT
        movie_title, num_critic_for_reviews,
        movie_facebook_likes, budget,
        gross, NTILE(5) OVER (ORDER BY gross DESC) AS tier
    FROM movies
    WHERE gross IS NOT NULL
) Q
GROUP BY Q.tier;
```





### _Concatenation_  
CONCAT ( \<col name\>, \<col name\>,...)  

## Date Manipulation  

### Functions
_CURRENT_DATE()_ Return current date.  
_CURRENT_TIME()_ Return current time.  
_DATE()_ Extract the date part of a date or
datetime expression.  
_DAY()_, _DAYOFMONTH()_ Return the day of the month (1-
31)  
_DAYOFWEEK()_ Return the weekday index of a
date or datetime expression.  
_MONTH()_ Return the month part of a date
or datetime expression.  
_YEAR()_ Return the year part of a date or
datetime expression.  
_DATE_ADD(date, INTERVAL value add unit)_  
Adds a time/date interval to a
date and then returns the date  



# Docker

## Images
+ An executable package that includes everything needed to run an application: code, runtime, libraries, environment variable configuration files
+ can build your own 

can find images at https://www.dockerhub.com  


## Container
+ a runtime instance of a image - is what the image becomes in memory when executed
+ once you have the image pulled you can start the container from the docker engine
+ containers isolate software from its environment.  

## Commands
### _List all images_   
docker image ls  

### _Delete a file_  

rm   

### _Continue command on new line_  

^  

### _Pull an image_  

docker pull \<docker IMAGE\>   

### _Remove image from computer_  

docker image rm -f \<IMAGE ID\>   

### _Run a container_  

docker run -it -d --rm ^  
-p hostPort:containerPort ^  
-v host-dir:container-dir ^  
(actual example  
docker run -it --rm ^  
-p 8890:8888 ^  
-v %cd%:/home/ubuntu/Workspace ^  
nycdsa/linux-toolkits) cd is the current directory  
\<docker IMAGE\>  
bash   

### _Options_  

-it runs a container in interactive processes.  
-d (optional) runs a container in the background in detached mode.  
--rm (optional) removes the container when it exits or when the daemon exits.   
-p hostPort:containerPort (optional) forwards a container᾿s port to the host.   
-v host-dir:container-dir (optional) mounts a host directory into a container directory so files can be shared between them.   
bash (optional) starts the command line of the container in the terminal.Depending how the image was built, you may or may not need it.   

### _Inspect running elements_  

docker ps  

### _Inspect stopped containers_  

docker ps -a  

### _Stop a container_  

exit  

### _Remove a stopped container_  

docker container rm <CONTAINER ID>    

only need to specify enough characters of the container to uniquely identify it  

### _Restart and Log back into container_  

docker restart <container id>   

docker exec -it <container id> bash  


# General Windows Terminal 
## Commands

### _Echo_
echo prints  
### _Change Directory_  
cd  
### _list files and directories_  
dir  

# Linux   

## Commands  
date (gets date)  

ssh (loginto remote server)  

scp (copy from or to a remote machine)  

wget or curl (download a webpage)  


### _Command help_  

command --help  

### _Show entire file system_  

ls <directory to list>   


### _Change directories_  

cd <pathname>  

cd or cd ~ changes to home directory  

cd .. changes to parent folder  


### _Make DIrectory_  

mkdir <directory name>  

mkdir -p ~/examples/multiple/levels/down  

(-p makes multiple nested directories regardless of weather parts of the specified path exist)  


### _Copy file or Folder_  

cp [-r] <source> <destination>  

-r argument means recursively for copying folders  

copy a file into home directory; note the .  
$ cp /etc/magic .  
copy a file into home directory with a new name  
$ cp /etc/hosts nethosts  
$ ls  

### _Move or rename files_  
mv <source> <Destination>

### _Move curser and keyboard shortcuts_
ctrl + a (begginging of line)  
crtl + e (end of line)  
crtl + u (delete line)
Tab (auto-complete) 

### _Remove files_
rm
rmdir or rm -r (removes empty folders)  

### _Quick create file_
touch <filename>

### _I/O redirection_
\> create  
\>\> append

### _Print Files or show contents_
cat <filename>
head <filename>  
less <filename>
Scroll up/down one line at a time with arrow keys.  
Use the space bar to scroll through a screen at a time.  
Use the / key to search for a term: /apple  
Press h to see a quick list of other options.  
Press q to exit less.  

### _Download file_
wget <url>

### _File permissions_ 
ls - l (long format) to show permissions  

The permissions are broken into 4 sections. For example: drwxr-xr--  

1. d: ‘-’ -> file, ‘d’ -> directory, ‘l’ -> link  

2. rwx: permissions for the owner  

3. r-x: permissions for members of the group owning the file  

4. r-x: permissions for other users  

Where ‘r’-> read, ‘w’-> write/delete, ‘x’-> execute, ‘-’-> no permission  



### _Show command line format_
echo $PS1  (PS1-4 exist)

### _change command prompt_  
export PS1 = "\\u \\t:$"   

will change prompt to user name and time followed by \"\:\$\"  


### _Clear screen_
crtl + L  

### _Stop process_
crtl + C   

### _Stop Program_
crtl + D  

### _print working dirrectory_
pwd

### _Relative Path_
./  (is current directory)

### _Parent Directory_
../  

### _home directory_
~  

### _show where a file is_
which <filename>  

### _change permission_
write = 2  

execute = 1  

read = 4  

chmod 744  

owner will be given 7 permission (sum of 4 + 1 + 2) 

group will be given 4 permission (sum of 3 + 1)  

other users will be given permission 4 (sum of 3 +1) 


### _Text Processing_
grep - Search through a given file using a string  

grep <word> <file1> [<file2]>  

wc - Count lines and words  

outputs lines/words/characters  

sort - Sort all lines in file  

  sort -k9 (key)(column 9 (counts from 1))  
  
  sort -k5 -n (sorts 5th column which contains numbers)  
  


# VI  
## commands  

### _Open vi_
vi <filename>  
will open filename or create it if it doesnt exist  

### _insert mode_
I  

a - insert after cursor  

i - insert before cursor  

o - insert a new line below  

O - insert a new line above  

ESC - exit insert mode 


### _command mode_
esc  

x - delete one character  
dw - delete one word  
dd - delete the line  
D - delete the rest of the line  
u - undo the last action  

### _exit VI_
ZZ save file and exit(capital letters)  
:wq (save and quit)  
:w save without exiting  
:q! exit without saving  

# Git
## workflow  

### _pull repo from remote_

-git init  
or  
-git clone  
write code  
-git add <file>  
<file> is now in staging area  
-git commit  
commit changes and opens editor to add a comment  
write code  
-git add <file>  
-git commit -m "messasge" 
revert changed git checkout <hash> or <head~ID>  
brings us to a detached head state  
-git checkout master (or main)  
reattaches head  
for checkouts that could cause conflicts  
-git revert <hashID>  
resolve conflicts  
-git add .  
-git commit -m "message"  
prepare to push to github  
change wd out of project repo  
create repo on github  
copy repo URL from 'code' button  
-git clone <git hub url>  
-git push  




## Commands  
###  _git init_ 
convert an existing, unversioned project to a Git repository or initialize a new empty repository.  

###  _git clone_  
copies an existing Git repository  

###  _git status_ 
show status of all tracked and untracked files 

###  _git log_  
full status of git commands
--stat includes a brief summary  
--oneline (condense each commit to a single line)    
--graph --decorate To include branches and the ref names:  

###  _git reflog_ 
get complete history in repo  

###  _git add <file> _ 

starts tracking <file>  
git add . (adds all files)  

###  _git commit_ 
commit changes  
-m "message"  
-a  does the add as well as commit  

###  _git show_ 
see changes that were made to tracked files  
git show <commit hash> to see textual differences   
git show HEAD reference to the currently checked-out commit/branch.  
git show HEAD~2 shows the second commit message  

###  _git checkout -- <file> _  
discard changes in working directory  
git checkout HEAD~2  

###  _git diff_  
To see what you’ve changed but not yet staged 

###  _git restore --staged <file>  _ 
to unstage <file>  

###  _git reset <hash ID>_ 
permanetly reverts code to hash ID

###  _Config _  
git config --global user.name "name"  
git config --global user.email email@email  



# Resources
Books for free:  Data Science at the Command line  
https://datascienceatthecommandline.com/  
Practical Statistics for Data Science
https://largepdf.net/practical-statistics-for-data-scientists-50-essential-concepts-using-r-and-python/  
Bayesian Methods for hackers
https://freecomputerbooks.com/Bayesian-Methods-for-Hackers.html




